#!/usr/bin/env python3
"""
ğŸ”§ Magentic-UI ç½‘ç»œè¿æ¥è§£å†³æ–¹æ¡ˆ
è‡ªåŠ¨è¯Šæ–­å’Œä¿®å¤ç½‘ç»œè¿æ¥é—®é¢˜
"""

import asyncio
import aiohttp
import os
from typing import Dict, Any

class NetworkSolutionManager:
    def __init__(self):
        self.config_files = {
            "stable": "config_stable.yaml",
            "original": "config.yaml"
        }
        
    async def test_api_endpoint(self, base_url: str, api_key: str, timeout: int = 10) -> bool:
        """æµ‹è¯•APIç«¯ç‚¹æ˜¯å¦å¯ç”¨"""
        try:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            timeout_config = aiohttp.ClientTimeout(total=timeout)
            async with aiohttp.ClientSession(timeout=timeout_config) as session:
                async with session.get(f"{base_url}/models", headers=headers) as response:
                    return response.status == 200
        except Exception:
            return False
    
    async def diagnose_network(self) -> Dict[str, Any]:
        """è¯Šæ–­ç½‘ç»œè¿æ¥çŠ¶å†µ"""
        print("ğŸ” å¼€å§‹ç½‘ç»œè¿æ¥è¯Šæ–­...")
        
        # è·å–ç¯å¢ƒå˜é‡
        openrouter_key = os.getenv("OPENROUTER_API_KEY", "")
        openai_key = os.getenv("OPENAI_API_KEY", "")
        
        results = {
            "openrouter_available": False,
            "openai_available": False,
            "basic_internet": False,
            "recommended_config": "stable"
        }
        
        # æµ‹è¯•åŸºç¡€ç½‘ç»œè¿æ¥
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get("https://www.google.com", timeout=aiohttp.ClientTimeout(total=5)) as response:
                    results["basic_internet"] = response.status == 200
        except:
            results["basic_internet"] = False
        
        print(f"âœ… åŸºç¡€ç½‘ç»œè¿æ¥: {'æ­£å¸¸' if results['basic_internet'] else 'å¼‚å¸¸'}")
        
        # æµ‹è¯• OpenRouter
        if openrouter_key:
            results["openrouter_available"] = await self.test_api_endpoint(
                "https://openrouter.ai/api/v1", openrouter_key
            )
            print(f"ğŸ”— OpenRouter API: {'å¯ç”¨' if results['openrouter_available'] else 'ä¸å¯ç”¨'}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ° OPENROUTER_API_KEY")
        
        # æµ‹è¯• OpenAI
        if openai_key:
            results["openai_available"] = await self.test_api_endpoint(
                "https://api.openai.com/v1", openai_key
            )
            print(f"ğŸ¤– OpenAI API: {'å¯ç”¨' if results['openai_available'] else 'ä¸å¯ç”¨'}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ° OPENAI_API_KEY")
        
        return results
    
    def create_optimal_config(self, diagnosis: Dict[str, Any]) -> str:
        """æ ¹æ®è¯Šæ–­ç»“æœåˆ›å»ºæœ€ä¼˜é…ç½®"""
        if diagnosis["openrouter_available"]:
            return self.create_openrouter_config()
        elif diagnosis["openai_available"]:
            return self.create_openai_config()
        else:
            return self.create_offline_config()
    
    def create_openrouter_config(self) -> str:
        """åˆ›å»ºOpenRouteré…ç½®"""
        return """# ğŸ”§ ä¼˜åŒ–çš„ OpenRouter é…ç½®
model_config: &client
  provider: autogen_ext.models.openai.OpenAIChatCompletionClient
  config:
    model: openai/gpt-3.5-turbo
    api_key: $OPENROUTER_API_KEY
    base_url: https://openrouter.ai/api/v1
    timeout: 180.0
    max_retries: 8
    model_info:
      vision: false
      function_calling: true
      json_output: false

orchestrator_client: *client
coder_client: *client
web_surfer_client: *client
file_surfer_client: *client
action_guard_client: *client

# ç®€åŒ–é…ç½®ä»¥æé«˜ç¨³å®šæ€§
cooperative_planning: true
autonomous_execution: false
max_actions_per_step: 3
multiple_tools_per_call: false
max_turns: 20
approval_policy: auto-conservative
browser_headless: true
action_guard_enabled: false
"""
    
    def create_openai_config(self) -> str:
        """åˆ›å»ºOpenAIé…ç½®"""
        return """# ğŸ”§ ä¼˜åŒ–çš„ OpenAI é…ç½®
model_config: &client
  provider: autogen_ext.models.openai.OpenAIChatCompletionClient
  config:
    model: gpt-3.5-turbo
    api_key: $OPENAI_API_KEY
    timeout: 180.0
    max_retries: 8
    model_info:
      vision: false
      function_calling: true
      json_output: false

orchestrator_client: *client
coder_client: *client
web_surfer_client: *client
file_surfer_client: *client
action_guard_client: *client

# ç®€åŒ–é…ç½®ä»¥æé«˜ç¨³å®šæ€§
cooperative_planning: true
autonomous_execution: false
max_actions_per_step: 3
multiple_tools_per_call: false
max_turns: 20
approval_policy: auto-conservative
browser_headless: true
action_guard_enabled: false
"""
    
    def create_offline_config(self) -> str:
        """åˆ›å»ºç¦»çº¿/æœ¬åœ°æ¨¡å‹é…ç½®"""
        return """# ğŸ”§ ç¦»çº¿æ¨¡å¼é…ç½® (éœ€è¦æœ¬åœ°Ollama)
model_config: &client
  provider: autogen_ext.models.ollama.OllamaChatCompletionClient
  config:
    model: qwen2.5:14b
    host: http://localhost:11434
    timeout: 300.0
    max_retries: 3
    model_info:
      vision: false
      function_calling: true
      json_output: false

orchestrator_client: *client
coder_client: *client
web_surfer_client: *client
file_surfer_client: *client
action_guard_client: *client

# ç¦»çº¿æ¨¡å¼é…ç½®
cooperative_planning: true
autonomous_execution: false
max_actions_per_step: 2
multiple_tools_per_call: false
max_turns: 15
approval_policy: auto-conservative
browser_headless: true
action_guard_enabled: false
"""
    
    async def apply_solution(self) -> bool:
        """åº”ç”¨è§£å†³æ–¹æ¡ˆ"""
        print("\nğŸ”§ å¼€å§‹åº”ç”¨ç½‘ç»œè¿æ¥è§£å†³æ–¹æ¡ˆ...")
        
        # è¯Šæ–­ç½‘ç»œ
        diagnosis = await self.diagnose_network()
        
        # åˆ›å»ºä¼˜åŒ–é…ç½®
        optimal_config = self.create_optimal_config(diagnosis)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_path = "config_optimized.yaml"
        with open(config_path, "w", encoding="utf-8") as f:
            f.write(optimal_config)
        
        print(f"\nâœ… å·²åˆ›å»ºä¼˜åŒ–é…ç½®æ–‡ä»¶: {config_path}")
        
        # ç»™å‡ºä½¿ç”¨å»ºè®®
        if diagnosis["openrouter_available"]:
            print("ğŸ¯ æ¨èä½¿ç”¨ OpenRouter API (æœ€ç¨³å®š)")
            print(f"å¯åŠ¨å‘½ä»¤: python load_env.py --config {config_path} --port 8081")
        elif diagnosis["openai_available"]:
            print("ğŸ¯ æ¨èä½¿ç”¨ OpenAI API")
            print(f"å¯åŠ¨å‘½ä»¤: python load_env.py --config {config_path} --port 8081")
        else:
            print("ğŸ¯ æ¨èä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹")
            print("è¯·å…ˆå®‰è£… Ollama: https://ollama.ai/")
            print("ç„¶åè¿è¡Œ: ollama pull qwen2.5:14b")
            print(f"æœ€åå¯åŠ¨: python load_env.py --config {config_path} --port 8081")
        
        return True

async def main():
    print("ğŸš€ Magentic-UI ç½‘ç»œè¿æ¥è§£å†³æ–¹æ¡ˆ")
    print("=" * 50)
    
    manager = NetworkSolutionManager()
    success = await manager.apply_solution()
    
    if success:
        print("\nâœ… è§£å†³æ–¹æ¡ˆå·²æˆåŠŸåº”ç”¨!")
        print("ğŸ‰ æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®å¯åŠ¨ Magentic-UI")
    else:
        print("\nâŒ è§£å†³æ–¹æ¡ˆåº”ç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    asyncio.run(main()) 