"""
å›¾åƒç”Ÿæˆå·¥å…· - æ”¯æŒå¤šç§OpenAIå…¼å®¹çš„å›¾åƒç”Ÿæˆæ¨¡å‹
"""

import base64
import asyncio
import logging
from typing import Dict, Any, Optional
import aiohttp
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ImageGenerationResult:
    """å›¾åƒç”Ÿæˆç»“æœ"""
    success: bool
    image_data: Optional[str] = None  # base64ç¼–ç çš„å›¾åƒæ•°æ®
    image_url: Optional[str] = None   # å›¾åƒURL
    error_message: Optional[str] = None
    model_used: Optional[str] = None
    generation_time: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None

@dataclass 
class ImageGenerationConfig:
    """å›¾åƒç”Ÿæˆé…ç½® - ä»é…ç½®æ–‡ä»¶åŠ¨æ€è·å–é»˜è®¤å€¼"""
    model: str = "dall-e-3"  # ğŸ”§ ä¿æŒä½œä¸ºé»˜è®¤å€¼ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼šä»é…ç½®æ–‡ä»¶è·å–
    size: str = "1024x1024"
    quality: str = "standard"  # "standard" or "hd"
    style: str = "vivid"       # "natural" or "vivid"
    response_format: str = "b64_json"  # "url" or "b64_json"
    n: int = 1

class ImageGenerationClient:
    """ç»Ÿä¸€çš„å›¾åƒç”Ÿæˆå®¢æˆ·ç«¯ï¼Œæ”¯æŒå¤šç§OpenAIå…¼å®¹çš„æ¨¡å‹"""
    
    # æ”¯æŒçš„æ¨¡å‹æ˜ å°„
    SUPPORTED_MODELS = {
        # OpenAI DALL-E
        "dall-e-3": {
            "provider": "openai",
            "sizes": ["1024x1024", "1792x1024", "1024x1792"],
            "qualities": ["standard", "hd"],
            "styles": ["natural", "vivid"]
        },
        "dall-e-2": {
            "provider": "openai", 
            "sizes": ["256x256", "512x512", "1024x1024"],
            "qualities": ["standard"],
            "styles": []
        },
        # Google Imagen
        "imagen-3.0-generate-002": {
            "provider": "google",
            "sizes": ["1024x1024", "1024x1536", "1536x1024"],
            "qualities": ["low", "medium", "high"],
            "styles": []
        },
        # Stable Diffusioné€šè¿‡OpenRouter
        "stability-ai/stable-diffusion-xl": {
            "provider": "stability",
            "sizes": ["1024x1024", "1152x896", "896x1152"],
            "qualities": ["standard"],
            "styles": []
        }
    }
    
    def __init__(self, 
                 api_key: str,
                 base_url: str = "https://api.openai.com/v1",  # ğŸ”§ ä¿æŒé»˜è®¤å€¼ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼šä»é…ç½®æ–‡ä»¶è·å–
                 default_model: str = "dall-e-3",  # ğŸ”§ ä¿æŒé»˜è®¤å€¼ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼šä»é…ç½®æ–‡ä»¶è·å–
                 timeout: int = 60):
        # å¦‚æœapi_keyä¸ºç©ºï¼Œå°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if not api_key:
            import os
            if base_url.startswith("https://api.openai.com"):
                api_key = os.getenv("OPENAI_API_KEY", "")
            elif "openrouter" in base_url:
                api_key = os.getenv("OPENROUTER_API_KEY", "")
            else:
                api_key = os.getenv("OPENAI_API_KEY", "")  # é»˜è®¤ä½¿ç”¨OpenAI
                
        self.api_key = api_key
        self.base_url = base_url.rstrip('/')
        self.default_model = default_model
        self.timeout = timeout
        
        # éªŒè¯å…³é”®é…ç½®
        if not self.api_key:
            logger.warning("âš ï¸ å›¾åƒç”ŸæˆAPIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡OPENAI_API_KEY")
        
        logger.info(f"ğŸ¨ å›¾åƒç”Ÿæˆå®¢æˆ·ç«¯åˆå§‹åŒ–: {base_url} (æ¨¡å‹: {default_model})")
        
    async def generate_image(self, 
                           prompt: str,
                           config: Optional[ImageGenerationConfig] = None) -> ImageGenerationResult:
        """
        ç”Ÿæˆå›¾åƒ
        
        Args:
            prompt: å›¾åƒæè¿°æç¤ºè¯
            config: ç”Ÿæˆé…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            
        Returns:
            ImageGenerationResult: ç”Ÿæˆç»“æœ
        """
        if config is None:
            config = ImageGenerationConfig(model=self.default_model)
            
        start_time = asyncio.get_event_loop().time()
        
        try:
            # éªŒè¯æ¨¡å‹å’Œå‚æ•°
            self._validate_config(config)
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = self._build_request_data(prompt, config)
            
            # å‘é€è¯·æ±‚
            result = await self._send_request(request_data)
            
            generation_time = asyncio.get_event_loop().time() - start_time
            
            return ImageGenerationResult(
                success=True,
                image_data=result.get("image_data"),
                image_url=result.get("image_url"),
                model_used=config.model,
                generation_time=generation_time,
                metadata=result.get("metadata", {})
            )
            
        except Exception as e:
            logger.error(f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}")
            generation_time = asyncio.get_event_loop().time() - start_time
            
            return ImageGenerationResult(
                success=False,
                error_message=str(e),
                model_used=config.model,
                generation_time=generation_time
            )
    
    def _validate_config(self, config: ImageGenerationConfig):
        """éªŒè¯é…ç½®å‚æ•°"""
        if config.model not in self.SUPPORTED_MODELS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {config.model}. æ”¯æŒçš„æ¨¡å‹: {list(self.SUPPORTED_MODELS.keys())}")
        
        model_info = self.SUPPORTED_MODELS[config.model]
        
        if config.size not in model_info["sizes"]:
            raise ValueError(f"æ¨¡å‹ {config.model} ä¸æ”¯æŒå°ºå¯¸ {config.size}")
        
        if config.quality not in model_info["qualities"]:
            raise ValueError(f"æ¨¡å‹ {config.model} ä¸æ”¯æŒè´¨é‡ {config.quality}")
        
        if model_info["styles"] and config.style not in model_info["styles"]:
            raise ValueError(f"æ¨¡å‹ {config.model} ä¸æ”¯æŒé£æ ¼ {config.style}")
    
    def _build_request_data(self, prompt: str, config: ImageGenerationConfig) -> Dict[str, Any]:
        """æ„å»ºè¯·æ±‚æ•°æ®"""
        data = {
            "model": config.model,
            "prompt": prompt,
            "n": config.n,
            "size": config.size,
            "response_format": config.response_format
        }
        
        # æ·»åŠ æ¨¡å‹ç‰¹å®šå‚æ•°
        model_info = self.SUPPORTED_MODELS[config.model]
        
        if model_info["provider"] == "openai":
            if config.quality in model_info["qualities"]:
                data["quality"] = config.quality
            if config.style and model_info["styles"]:
                data["style"] = config.style
        elif model_info["provider"] == "google":
            # Imagenç‰¹å®šå‚æ•°
            data["quality"] = config.quality
        
        return data
    
    async def _send_request(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """å‘é€å›¾åƒç”Ÿæˆè¯·æ±‚"""
        url = f"{self.base_url}/images/generations"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
            async with session.post(url, headers=headers, json=request_data) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥ (çŠ¶æ€ç : {response.status}): {error_text}")
                
                result = await response.json()
                
                # å¤„ç†å“åº”æ•°æ®
                if "data" not in result or not result["data"]:
                    raise Exception("APIå“åº”ä¸­æ²¡æœ‰å›¾åƒæ•°æ®")
                
                image_info = result["data"][0]
                
                processed_result = {
                    "metadata": {
                        "revised_prompt": image_info.get("revised_prompt"),
                        "response": result
                    }
                }
                
                if "b64_json" in image_info:
                    processed_result["image_data"] = image_info["b64_json"]
                elif "url" in image_info:
                    processed_result["image_url"] = image_info["url"]
                    # å¦‚æœéœ€è¦ï¼Œå¯ä»¥ä¸‹è½½å›¾åƒå¹¶è½¬æ¢ä¸ºbase64
                    if request_data.get("response_format") == "b64_json":
                        processed_result["image_data"] = await self._download_and_encode(image_info["url"])
                
                return processed_result
    
    async def _download_and_encode(self, image_url: str) -> str:
        """ä¸‹è½½å›¾åƒå¹¶ç¼–ç ä¸ºbase64"""
        async with aiohttp.ClientSession() as session:
            async with session.get(image_url) as response:
                if response.status == 200:
                    image_bytes = await response.read()
                    return base64.b64encode(image_bytes).decode('utf-8')
                else:
                    raise Exception(f"ä¸‹è½½å›¾åƒå¤±è´¥: {response.status}")
    
    @classmethod
    def from_chat_client_config(cls, 
                              chat_client_config: Dict[str, Any],
                              image_model: Optional[str] = None) -> "ImageGenerationClient":
        """
        ä»ç°æœ‰çš„èŠå¤©å®¢æˆ·ç«¯é…ç½®åˆ›å»ºå›¾åƒç”Ÿæˆå®¢æˆ·ç«¯
        
        Args:
            chat_client_config: ç°æœ‰çš„èŠå¤©å®¢æˆ·ç«¯é…ç½®
            image_model: æŒ‡å®šçš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¦‚æœä¸ºNoneåˆ™å°è¯•è‡ªåŠ¨é€‰æ‹©
            
        Returns:
            ImageGenerationClientå®ä¾‹
        """
        config = chat_client_config.get("config", {})
        
        api_key = config.get("api_key")
        base_url = config.get("base_url", "https://api.openai.com/v1")
        
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°APIå¯†é’¥")
        
        # è‡ªåŠ¨é€‰æ‹©å›¾åƒæ¨¡å‹
        if image_model is None:
            current_model = config.get("model", "")
            if "gemini" in current_model.lower():
                image_model = "imagen-3.0-generate-002"
            elif "gpt" in current_model.lower() or "openai" in base_url.lower():
                image_model = "dall-e-3"
            else:
                image_model = "dall-e-3"  # é»˜è®¤
        
        return cls(
            api_key=api_key,
            base_url=base_url,
            default_model=image_model,
            timeout=config.get("timeout", 60)
        )

# ä¾¿åˆ©å‡½æ•°
async def quick_generate_image(prompt: str, 
                             api_key: str,
                             base_url: str = "https://api.openai.com/v1",
                             model: str = "dall-e-3") -> ImageGenerationResult:
    """å¿«é€Ÿç”Ÿæˆå›¾åƒçš„ä¾¿åˆ©å‡½æ•°"""
    client = ImageGenerationClient(api_key, base_url, model)
    config = ImageGenerationConfig(model=model)
    return await client.generate_image(prompt, config) 