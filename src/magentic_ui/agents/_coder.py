import asyncio
from pathlib import Path
import shutil
import tempfile
from typing import AsyncGenerator, List, Sequence, Optional
import re
from typing import Any, Mapping
import uuid
from loguru import logger
from datetime import datetime
from pydantic import Field
from autogen_core import CancellationToken, ComponentModel, Component
from autogen_core.models import (
    ChatCompletionClient,
    UserMessage,
    SystemMessage,
)
from pydantic import BaseModel
from typing_extensions import Self

from autogen_agentchat.agents import BaseChatAgent
from autogen_core.code_executor import CodeBlock, CodeExecutor
from autogen_core.model_context import (
    ChatCompletionContext,
    TokenLimitedChatCompletionContext,
)
from autogen_agentchat.base import Response
from autogen_agentchat.state import BaseState
from autogen_agentchat.messages import (
    BaseAgentEvent,
    BaseChatMessage,
    TextMessage,
    MessageFactory,
    MultiModalMessage,
)
from autogen_core.code_executor import CodeResult
from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor
from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor

# ä½¿ç”¨ç›¸å¯¹å¯¼å…¥é¿å…å¾ªç¯å¯¼å…¥é—®é¢˜
from ..utils import thread_to_context
from ._utils import exec_command_umask_patched

from ..approval_guard import BaseApprovalGuard
from ..guarded_action import ApprovalDeniedError, TrivialGuardedAction
from ..utils.conversation_storage_manager import add_conversation_file, add_conversation_text_file

DockerCommandLineCodeExecutor._execute_command = exec_command_umask_patched  # type: ignore


def _extract_markdown_code_blocks(markdown_text: str) -> List[CodeBlock]:
    pattern = re.compile(r"```(?:\s*([\w\+\-]+))?\n([\s\S]*?)```")
    matches = pattern.findall(markdown_text)
    code_blocks: List[CodeBlock] = []
    for match in matches:
        language = match[0].strip() if match[0] else ""
        code_content = match[1]
        code_blocks.append(CodeBlock(code=code_content, language=language))
    return code_blocks


async def _invoke_action_guard(
    thread: Sequence[BaseChatMessage | BaseAgentEvent],
    delta: Sequence[BaseChatMessage | BaseAgentEvent],
    code_message: TextMessage,
    agent_name: str,
    model_client: ChatCompletionClient,
    approval_guard: BaseApprovalGuard | None,
) -> None:
    # Get approval for the coding request. We could conceivably do extra work to enable interactive approval here,
    # but the value for many users is likely to be low, as it may not be appropriate to assume knowledge of coding,
    # and thus the user will not have the context necessary to approve/deny the incremental execution of code blocks.
    guarded_action = TrivialGuardedAction("coding", baseline_override="maybe")

    # Note that delta already contains the code message.
    assert delta[-1] == code_message

    thread = list(thread) + list(delta)

    context = thread_to_context(
        thread,
        agent_name,
        is_multimodal=model_client.model_info["vision"],
    )
    action_description_for_user = TextMessage(
        content="Do you want to execute the code above?",
        source=agent_name,
    )

    await guarded_action.invoke_with_approval(
        {}, code_message, context, approval_guard, action_description_for_user
    )


async def _coding_and_debug(
    system_prompt: str,
    thread: Sequence[BaseChatMessage],
    agent_name: str,
    model_client: ChatCompletionClient,
    code_executor: CodeExecutor,
    max_debug_rounds: int,
    cancellation_token: CancellationToken,
    model_context: ChatCompletionContext,
    approval_guard: BaseApprovalGuard | None,
) -> AsyncGenerator[TextMessage | bool, None]:
    """Write and debug code using the model and executor.

    It generates code based on the system prompt and the thread of messages,
    executes it, and returns the output. It continues to generate and execute
    code until the maximum number of debug rounds is reached or the code
    executes successfully.

    When the cancellation token is set, the execution will stop.
    Args:
        system_prompt (str): The system prompt to guide the model.
        thread (Sequence[BaseChatMessage]): The thread of messages to use as context.
        agent_name (str): The name of the agent.
        model_client (ChatCompletionClient): The model client to use for code generation.
        code_executor (CodeExecutor): The code executor to use for executing the code.
        max_debug_rounds (int): The maximum number of debug rounds to perform.
        cancellation_token (CancellationToken): The cancellation token to stop execution.
        model_context (ChatCompletionContext): The context for the model.
        approval_guard (ApprovalGuard | None): The approval guard to use for code execution.

    Yields:
        TextMessage: The intermediate messages generated by the model and executor.
        bool: A flag indicating whether any code execution was performed.

    Raises:
        ApprovalDeniedError: If the user denies the approval for the coding request.
    """
    # The list of new messages to be added to the thread.
    delta: Sequence[BaseChatMessage | BaseAgentEvent] = []
    executed_code = False

    for i in range(max_debug_rounds):
        # Add system prompt as the last message before generation
        current_thread = (
            list(thread)
            + list(delta)
            + [TextMessage(source="user", content=system_prompt)]
        )

        # create an LLM context from system message, global chat history, and inner messages
        context = [SystemMessage(content=system_prompt)] + thread_to_context(
            current_thread,
            agent_name,
            is_multimodal=model_client.model_info["vision"],
        )

        # Re-initialize model context to meet token limit quota
        try:
            await model_context.clear()
            for msg in context:
                await model_context.add_message(msg)
            token_limited_context = await model_context.get_messages()
        except Exception:
            token_limited_context = context
        # Generate code using the model.
        create_result = await model_client.create(
            messages=token_limited_context, cancellation_token=cancellation_token
        )
        assert isinstance(create_result.content, str)
        code_msg = TextMessage(
            source=agent_name + "-llm",
            metadata={"internal": "no", "type": "potential_code"},
            content=create_result.content,
        )
        # add LLM's response to the current thread.
        delta.append(code_msg)
        yield code_msg

        # extract code blocks from the LLM's response
        code_block_list = _extract_markdown_code_blocks(create_result.content)
        # if no code to execute, return
        if len(code_block_list) == 0:
            break

        # Now that we know we have code to execute, make sure we have permission to do so.
        # Note that we will be getting this permission per round of code/execute/debug.
        if approval_guard is not None:
            await _invoke_action_guard(
                thread=thread,
                delta=delta,
                code_message=code_msg,  # note that this `code_msg is delta[-1]`
                agent_name=agent_name,
                model_client=model_client,
                approval_guard=approval_guard,
            )

        code_output_list: List[str] = []
        exit_code_list: List[int] = []
        executed_code = True
        try:
            for cb in code_block_list:
                # execute the code block
                exit_code: int = 1
                encountered_exception: bool = False
                code_output: str = ""
                result: CodeResult | None = None
                try:
                    result = await code_executor.execute_code_blocks(
                        [cb], cancellation_token
                    )
                    exit_code = result.exit_code or 0
                    code_output = result.output
                except Exception as e:
                    code_output = str(e)
                    encountered_exception = True
                if encountered_exception or result is None:
                    code_output = f"An exception occurred while executing the code block: {code_output}"
                elif code_output.strip() == "":
                    # No output
                    code_output = f"The script ran but produced no output to console. The POSIX exit code was: {result.exit_code}. If you were expecting output, consider revising the script to ensure content is printed to stdout."
                elif exit_code != 0:
                    # Error
                    code_output = f"The script ran, then exited with an error (POSIX exit code: {result.exit_code})\nIts output was:\n{result.output}"
                code_output_list.append(code_output)
                code_output_msg = TextMessage(
                    source=agent_name + "-executor",
                    metadata={"internal": "no", "type": "code_execution"},
                    content=f"Execution result of code block {i + 1}:\n```console\n{code_output}\n```",
                )
                exit_code_list.append(exit_code)
                yield code_output_msg

            final_code_output = ""
            for i, code_output in enumerate(code_output_list):
                final_code_output += f"\n\nExecution Result of Code Block {i + 1}:\n```console\n{code_output}\n```"

            # add executors response to thread.
            executor_msg = TextMessage(
                source=agent_name + "-executor",
                metadata={"internal": "yes"},
                content=final_code_output,
            )
            delta.append(executor_msg)
            yield executor_msg

            # break if the code execution was successful
            if all([code_output == 0 for code_output in exit_code_list]):
                break
        except asyncio.TimeoutError:
            # If the task times out, we treat it as an error.
            executor_msg = TextMessage(
                source=agent_name + "-executor",
                metadata={"internal": "yes"},
                content="Code execution timed out.",
            )
            delta.append(executor_msg)
            yield executor_msg

    yield executed_code


async def _summarize_coding(
    agent_name: str,
    model_client: ChatCompletionClient,
    thread: Sequence[BaseChatMessage | BaseAgentEvent],
    cancellation_token: CancellationToken,
    model_context: ChatCompletionContext,
) -> TextMessage:
    # Create a summary from the inner messages using an extra LLM call.
    input_messages = (
        [SystemMessage(content="You are an agent that can write and debug code")]
        + thread_to_context(
            list(thread), agent_name, is_multimodal=model_client.model_info["vision"]
        )
        + [
            UserMessage(
                content="""
                The above is a transcript of your previous messages and a request that was given to you in the begining.
                You need to summarize them to answer the request given to you. Generate a summary of everything that happened.
                If there was code that was executed, please copy the final code that was executed without errors.
                Don't mention that this is a summary, just give the summary.""",
                source="user",
            )
        ]
    )

    # Re-initialize model context to meet token limit quota
    try:
        await model_context.clear()
        for msg in input_messages:
            await model_context.add_message(msg)
        token_limited_input_messages = await model_context.get_messages()
    except Exception:
        token_limited_input_messages = input_messages

    summary_result = await model_client.create(
        messages=token_limited_input_messages, cancellation_token=cancellation_token
    )
    assert isinstance(summary_result.content, str)
    return TextMessage(
        source=agent_name,
        metadata={"internal": "yes"},
        content=summary_result.content,
    )


class CoderAgentConfig(BaseModel):
    name: str
    model_client: ComponentModel
    description: str = """
    An agent that can write and execute code to solve tasks or use its language skills to summarize, write, solve math and logic problems.
    It understands images and can use them to help it complete the task.
    It can access files if given the path and manipulate them using python code. Use the coder if you want to manipulate a file or read a csv or excel files.
    """
    max_debug_rounds: int = 3
    summarize_output: bool = False
    # Optionally add code_executor config if needed


class CoderAgentState(BaseState):
    chat_history: List[BaseChatMessage] = Field(default_factory=list[BaseChatMessage])
    type: str = Field(default="CoderAgentState")


class CoderAgent(BaseChatAgent, Component[CoderAgentConfig]):
    """An agent capable of writing, executing, and debugging code.

    The agent uses either a local or Docker-based code executor to run the generated code
    in a controlled environment. It maintains a chat history and can be paused/resumed
    during execution.
    """

    component_type = "agent"
    component_config_schema = CoderAgentConfig
    component_provider_override = "magentic_ui.agents.CoderAgent"

    DEFAULT_DESCRIPTION = """
    An agent that can write and execute code to solve tasks or use its language skills to summarize, write, solve math and logic problems.
    It understands images and can use them to help it complete the task.
    It can access files if given the path and manipulate them using python code. Use the coder if you want to manipulate a file or read a csv or excel files.
    In a single step when you ask the agent to do something: it can write code, and then immediately execute the code. If there are errors it can debug the code and try again. 
    """

    system_prompt_coder_template = """
    You are helpful assistant.
    In addition to responding with text you can write code and execute code that you generate.
    The date today is: {date_today}

    ğŸ”§ IMPORTANT: You can handle both CODE and DOCUMENT tasks:
    
    For DOCUMENT CREATION tasks (like product introductions, summaries, reports):
    - You can create markdown files, HTML files, and other documents
    - Use Python code to generate and save these documents
    - Always confirm the document was created successfully
    - Provide clear completion messages when documents are ready
    - Support full markdownâ†’HTMLâ†’PDF conversion workflow
    
    For CODE tasks:
    - Generate py or sh code blocks in the order you'd like your code to be executed
    - Code block must indicate language type
    - Do not try to predict the answer of execution
    
    ğŸ¯ TASK RECOGNITION: 
    - If asked to create product introductions, summaries, or documentation â†’ Use Python to generate markdown/HTML files
    - If asked to perform calculations, data analysis, or programming â†’ Use appropriate code
    - If asked to create visual content â†’ Use plotting/image generation code
    - If asked for markdownâ†’HTMLâ†’PDF conversion â†’ Execute complete workflow
    - Always output clear completion confirmations

    ğŸ”„ DOCUMENT WORKFLOW SUPPORT:
    For markdownâ†’HTMLâ†’PDF conversion tasks:
    1. Collect information from chat history (web_surfer, file_surfer, image_generator outputs)
    2. Create well-structured markdown content
    3. Convert markdown to styled HTML with proper layout
    4. Generate final PDF with embedded images
    5. Confirm each step completion clearly

    Rules to follow for Code:
    - Generate py or sh code blocks in the order you'd like your code to be executed.
    - Code block must indicate language type. Do not try to predict the answer of execution. Code blocks will be automatically executed for you.
    - If you want to stop executing code, make sure to not write any code in your message and your turn will be over.
    - Do not generate code that relies on API keys that you don't have access to. Try different approaches.

    Tips:
    - You don't have to generate code if the task is not related to code, for instance writing a poem, paraphrasing a text, etc.
    - If you are asked to solve math or logical problems, first try to answer them without code and then if needed try to use python to solve them.
    - You have access to the standard Python libraries in addition to numpy, pandas, scikit-learn, matplotlib, pillow, requests, beautifulsoup4.
    - If you need to use an external library, write first a shell script that installs the library first using pip install, then add code blocks to use the library.
    - Always use print statements to output your work and partial results.
    - For data visualization and plots, use matplotlib with proper error handling. Always save plots to files with the right extension for display.
    - When creating plots with matplotlib, use the following error-resistant pattern:
      ```python
      import matplotlib
      matplotlib.use('Agg')  # Use non-interactive backend
      import matplotlib.pyplot as plt
      
      try:
          # Your plotting code here
          plt.savefig('filename.png', dpi=300, bbox_inches='tight')
          plt.close()  # Always close to free memory
          print("Plot saved successfully to filename.png")
      except Exception as e:
          print(f"Error creating plot: {{e}}")
          plt.close()  # Ensure cleanup even on error
      ```
    - For simple drawing or diagram requests, consider if the user's model has vision/multimodal capabilities that might be more appropriate than code-based plotting.

   VERY IMPORTANT: If you intend to write code to be executed, do not end your response without a code block. If you want to write code you must provide a code block in the current generation.
    
    ğŸ“‹ DOCUMENT CREATION TEMPLATES:
    
    For markdown to HTML conversion:
    ```python
    import markdown
    from pathlib import Path
    
    # Create styled HTML with embedded CSS
    html_template = '''<!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{{title}}</title>
        <style>
            body {{{{ 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                line-height: 1.6;
                color: #333;
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
                background-color: #fff;
            }}}}
            h1, h2, h3 {{{{ color: #2c5282; margin-top: 2em; }}}}
            h1 {{{{ border-bottom: 3px solid #2c5282; padding-bottom: 10px; }}}}
            img {{{{ max-width: 100%; height: auto; margin: 20px 0; border-radius: 8px; }}}}
            .product-spec {{{{ 
                background: #f7fafc; 
                border-left: 4px solid #4299e1; 
                padding: 1em; 
                margin: 1em 0; 
            }}}}
            .highlight {{{{ background-color: #fff3cd; padding: 2px 4px; }}}}
        </style>
    </head>
    <body>
        {{content}}
    </body>
    </html>'''
    
    # Convert markdown to HTML
    md_content = Path('document.md').read_text(encoding='utf-8')
    html_content = markdown.markdown(md_content, extensions=['extra', 'codehilite'])
    final_html = html_template.format(title="äº§å“ä»‹ç»", content=html_content)
    
    Path('document.html').write_text(final_html, encoding='utf-8')
    print("âœ… HTMLæ–‡æ¡£åˆ›å»ºå®Œæˆ: document.html")
    ```
    
    For HTML to PDF conversion:
    ```python
    # Install weasyprint if needed
    try:
        import weasyprint
    except ImportError:
        import subprocess
        subprocess.run(['pip', 'install', 'weasyprint'], check=True)
        import weasyprint
    
    from pathlib import Path
    
    # Convert HTML to PDF
    html_file = 'document.html'
    pdf_file = 'document.pdf'
    
    if Path(html_file).exists():
        weasyprint.HTML(filename=html_file).write_pdf(pdf_file)
        print(f"âœ… PDFæ–‡æ¡£åˆ›å»ºå®Œæˆ: {{pdf_file}}")
        print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {{Path(pdf_file).stat().st_size / 1024:.1f}} KB")
    else:
        print(f"âŒ HTMLæ–‡ä»¶ä¸å­˜åœ¨: {{html_file}}")
    ```
    """

    def __init__(
        self,
        name: str,
        model_client: ChatCompletionClient,
        model_context_token_limit: int = 128000,
        description: str = DEFAULT_DESCRIPTION,
        max_debug_rounds: int = 3,
        summarize_output: bool = False,
        code_executor: Optional[CodeExecutor] = None,
        work_dir: Path | str | None = None,
        bind_dir: Path | str | None = None,
        use_local_executor: bool = False,
        approval_guard: BaseApprovalGuard | None = None,
        session_id: int = None,
    ) -> None:
        """Initialize the CoderAgent.

        Args:
            name (str): The name of the agent
            model_client (ChatCompletionClient): The language model client to use
            description (str, optional): Description of the agent's capabilities. Default: DEFAULT_DESCRIPTION.
            max_debug_rounds (int, optional): Maximum number of code debugging iterations. Default: 3.
            summarize_output (bool, optional): Whether to summarize code execution results. Default: False.
            code_executor (Optional[CodeExecutor], optional): Custom code executor to use. Default: None.
            work_dir (Path | str | None, optional): Working directory for code execution. Default: None.
            bind_dir (Path | str | None, optional): Directory to bind for Docker executor. Default: None.
            use_local_executor (bool, optional): Whether to use local instead of Docker executor. Default: False.
        """
        super().__init__(name, description)
        self._model_client = model_client
        self._model_context = TokenLimitedChatCompletionContext(
            model_client, token_limit=model_context_token_limit
        )
        self._chat_history: List[BaseChatMessage] = []
        self._max_debug_rounds = max_debug_rounds
        self._summarize_output = summarize_output
        self.is_paused = False
        self._paused = asyncio.Event()
        self._approval_guard = approval_guard
        self.session_id = session_id  # ğŸ”§ æ–°å¢ï¼šå¯¹è¯ä¼šè¯ID

        if work_dir is None:
            self._work_dir = Path(tempfile.mkdtemp())
            self._cleanup_work_dir = True
        else:
            self._work_dir = Path(work_dir)
            self._cleanup_work_dir = False
        if code_executor:
            self._code_executor = code_executor
        elif use_local_executor:
            self._code_executor = LocalCommandLineCodeExecutor(work_dir=self._work_dir)
        else:
            name = f"{name}-{uuid.uuid4()}"
            self._code_executor = DockerCommandLineCodeExecutor(
                container_name=name,
                image="magentic-ui-python-env",
                work_dir=self._work_dir,
                bind_dir=bind_dir,
                delete_tmp_files=True,
            )

    async def lazy_init(self) -> None:
        """Initialize the code executor if it has a start method.

        This method is called after initialization to set up any async resources
        needed by the code executor.
        """
        if self._code_executor:
            # check if the code executor has a start method
            if hasattr(self._code_executor, "start"):
                # TODO: we should add a no-op start() method to the base class.
                await self._code_executor.start()  # type: ignore

    async def close(self) -> None:
        """Clean up resources used by the agent.

        This method:
        - Stops the code executor
        - Removes the work directory if it was created
        - Closes the model client
        """
        logger.info("Closing Coder...")
        await self._code_executor.stop()
        # Remove the work directory if it was created.
        if self._cleanup_work_dir and self._work_dir.exists():
            await asyncio.to_thread(shutil.rmtree, self._work_dir)
        # Close the model client.
        await self._model_client.close()

    async def pause(self) -> None:
        """Pause the agent by setting the paused state."""
        self.is_paused = True
        self._paused.set()

    async def resume(self) -> None:
        """Resume the agent by clearing the paused state."""
        self.is_paused = False
        self._paused.clear()

    @property
    def produced_message_types(self) -> Sequence[type[BaseChatMessage]]:
        """Get the types of messages produced by the agent."""
        return (TextMessage,)

    async def on_messages(
        self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken
    ) -> Response:
        """Handle incoming messages and return a single response. Calls the on_messages_stream."""
        response: Response | None = None
        async for message in self.on_messages_stream(messages, cancellation_token):
            if isinstance(message, Response):
                response = message
        assert response is not None
        return response

    async def on_messages_stream(
        self, messages: Sequence[BaseChatMessage], cancellation_token: CancellationToken
    ) -> AsyncGenerator[BaseAgentEvent | BaseChatMessage | Response, None]:
        """Handle incoming messages and yield responses as a stream. Append the request to agents chat history."""
        if self.is_paused:
            yield Response(
                chat_message=TextMessage(
                    content="The Coder is paused.",
                    source=self.name,
                    metadata={"internal": "yes"},
                )
            )
            return
        self._chat_history.extend(messages)
        last_message_received: BaseChatMessage = messages[-1]
        inner_messages: List[BaseChatMessage] = []

        # ğŸ”§ æ–°å¢ï¼šæ£€æµ‹æ–‡æ¡£åˆ›å»ºä»»åŠ¡ï¼ˆä»…å¤„ç†TextMessageï¼‰
        is_document_task = False
        is_pdf_task = False
        is_html_task = False
        has_reference_info = False
        has_info_from_history = False
        available_info = ""
        enhanced_system_prompt = ""
        
        task_content = ""
        if isinstance(last_message_received, TextMessage):
            task_content = last_message_received.content.lower()
            is_document_task = any(keyword in task_content for keyword in [
                "äº§å“ä»‹ç»", "markdown", "æ€»ç»“", "åˆ›å»º", "æ–‡æ¡£", "ä»‹ç»", "æ”¶é›†ä¿¡æ¯",
                "product introduction", "create", "document", "summary", "gather information",
                "html", "pdf", "è½¬æ¢", "convert", "format", "æ’ç‰ˆ"
            ])
        
        # ğŸ”§ æ”¹è¿›æ–‡æ¡£åˆ›å»ºä»»åŠ¡å¤„ç†é€»è¾‘
        if is_document_task:
            # æ£€æŸ¥æ˜¯å¦æ˜¯PDFè½¬æ¢ä»»åŠ¡
            is_pdf_task = any(keyword in task_content for keyword in [
                "pdf", "è½¬pdf", "è¾“å‡ºpdf", "ç”Ÿæˆpdf", "convert to pdf", "generate pdf"
            ])
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯HTMLè½¬æ¢ä»»åŠ¡
            is_html_task = any(keyword in task_content for keyword in [
                "html", "è½¬html", "htmlæ ¼å¼", "convert to html", "format html", "æ’ç‰ˆ"
            ])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‚è€ƒä¿¡æ¯æˆ–æ•°æ®
            has_reference_info = any(keyword in task_content for keyword in [
                "åŸºäº", "å‚è€ƒ", "æ ¹æ®", "ä¿¡æ¯", "èµ„æ–™", "æ•°æ®", "å†…å®¹", "æ¥æº", "ç½‘ç«™",
                "based on", "reference", "according to", "information", "data", "content", "source", "website"
            ])
            
            # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥èŠå¤©å†å²ä¸­æ˜¯å¦æœ‰web_surferæˆ–å…¶ä»–agentæä¾›çš„ä¿¡æ¯
            # æœç´¢èŠå¤©å†å²ä¸­çš„ä¿¡æ¯
            for msg in self._chat_history[-10:]:  # æ£€æŸ¥æœ€è¿‘10æ¡æ¶ˆæ¯
                if hasattr(msg, 'source') and msg.source in ["web_surfer", "file_surfer", "image_generator"]:
                    if isinstance(msg, TextMessage) and len(msg.content) > 50:
                        has_info_from_history = True
                        available_info += f"\næ¥æº ({msg.source}):\n{msg.content[:500]}...\n"
                    elif isinstance(msg, MultiModalMessage):
                        # å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯ - æå–æ–‡æœ¬å†…å®¹
                        try:
                            text_parts = [part for part in msg.content if isinstance(part, str)]
                            if text_parts:
                                text_content = " ".join(text_parts)
                                if len(text_content) > 50:
                                    has_info_from_history = True
                                    available_info += f"\næ¥æº ({msg.source}):\n{text_content[:500]}...\n"
                        except (TypeError, AttributeError):
                            # å¦‚æœæ— æ³•è¿­ä»£contentï¼Œè·³è¿‡
                            pass
            
            # ğŸ”§ å¦‚æœæœ‰ä¿¡æ¯å¯ç”¨ï¼Œç›´æ¥æ‰§è¡Œæ–‡æ¡£åˆ›å»ºä»»åŠ¡
            if has_info_from_history or has_reference_info or is_html_task or is_pdf_task:
                # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºï¼ŒåŒ…å«å…·ä½“çš„ä»»åŠ¡æŒ‡å¯¼
                enhanced_system_prompt = self.system_prompt_coder_template.format(
                    date_today=datetime.now().strftime("%Y-%m-%d")
                ) + f"""

ğŸ¯ **å½“å‰ä»»åŠ¡ç±»å‹**: æ–‡æ¡£åˆ›å»ºä»»åŠ¡

ğŸ“‹ **ä»»åŠ¡è¯†åˆ«**:
- æ–‡æ¡£åˆ›å»ºä»»åŠ¡: {'æ˜¯' if is_document_task else 'å¦'}
- HTMLè½¬æ¢ä»»åŠ¡: {'æ˜¯' if is_html_task else 'å¦'}
- PDFè½¬æ¢ä»»åŠ¡: {'æ˜¯' if is_pdf_task else 'å¦'}
- æœ‰å‚è€ƒä¿¡æ¯: {'æ˜¯' if has_info_from_history or has_reference_info else 'å¦'}

ğŸ“š **å¯ç”¨ä¿¡æ¯**:
{available_info if available_info else "è¯·åŸºäºä»»åŠ¡è¦æ±‚åˆ›å»ºæ–‡æ¡£"}

ğŸ”§ **æ‰§è¡ŒæŒ‡å¯¼**:
1. å¯¹äºMarkdownæ–‡æ¡£åˆ›å»ºï¼šåˆ›å»º.mdæ–‡ä»¶å¹¶ä¿å­˜
2. å¯¹äºHTMLè½¬æ¢ï¼šå°†markdownè½¬æ¢ä¸ºHTMLæ ¼å¼
3. å¯¹äºPDFè½¬æ¢ï¼šä½¿ç”¨ä»¥ä¸‹ä»£ç æ¨¡æ¿ï¼š

```python
# PDFè½¬æ¢ç¤ºä¾‹ä»£ç 
import weasyprint
from pathlib import Path

# å¦‚æœæ²¡æœ‰weasyprintï¼Œå…ˆå®‰è£…
try:
    import weasyprint
except ImportError:
    import subprocess
    subprocess.run(['pip', 'install', 'weasyprint'], check=True)
    import weasyprint

# HTMLè½¬PDF
html_content = '''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>äº§å“ä»‹ç»</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        h1 {{ color: #333; }}
        h2 {{ color: #666; }}
        p {{ line-height: 1.6; }}
    </style>
</head>
<body>
    <h1>360å…¨æ™¯ç›¸æœºäº§å“ä»‹ç»</h1>
    <!-- åœ¨è¿™é‡Œæ’å…¥å…·ä½“å†…å®¹ -->
</body>
</html>'''

# ä¿å­˜HTMLå¹¶è½¬æ¢ä¸ºPDF
Path('product_introduction.html').write_text(html_content, encoding='utf-8')
weasyprint.HTML(string=html_content).write_pdf('product_introduction.pdf')
print("âœ… PDFæ–‡ä»¶å·²ç”Ÿæˆ: product_introduction.pdf")
```

âš ï¸ **é‡è¦**: å¿…é¡»åœ¨ä»£ç æ‰§è¡Œåæä¾›æ˜ç¡®çš„å®Œæˆç¡®è®¤æ¶ˆæ¯ï¼
"""
                
                # ç›´æ¥æ‰§è¡Œæ–‡æ¡£åˆ›å»ºä»»åŠ¡ï¼Œä¸å†è¯¢é—®ä¿¡æ¯
                pass  # ç»§ç»­æ‰§è¡Œæ­£å¸¸çš„ä»£ç ç”Ÿæˆæµç¨‹
            else:
                # ğŸ”§ åªåœ¨çœŸæ­£ç¼ºå°‘ä¿¡æ¯æ—¶æ‰è¯¢é—®
                yield Response(
                    chat_message=TextMessage(
                        content="æˆ‘ç†è§£æ‚¨éœ€è¦åˆ›å»ºäº§å“ä»‹ç»æ–‡æ¡£ã€‚æˆ‘çœ‹åˆ°æ‚¨æƒ³è¦åˆ›å»º360å…¨æ™¯ç›¸æœºçš„äº§å“ä»‹ç»ã€‚è®©æˆ‘åŸºäºä¸€èˆ¬çš„360å…¨æ™¯ç›¸æœºçŸ¥è¯†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªåŸºç¡€çš„äº§å“ä»‹ç»æ–‡æ¡£ã€‚",
                        source=self.name,
                        metadata={"internal": "no"},
                    )
                )
                # ä¸è¦returnï¼Œç»§ç»­æ‰§è¡Œä»£ç ç”Ÿæˆ

        # Set up the cancellation token for the code execution.
        code_execution_token = CancellationToken()

        # Cancel the code execution if the handler's cancellation token is set.
        cancellation_token.add_callback(lambda: code_execution_token.cancel())

        # Set up background task to monitor the pause event and cancel the code execution if paused.
        async def monitor_pause() -> None:
            await self._paused.wait()
            code_execution_token.cancel()

        monitor_pause_task = asyncio.create_task(monitor_pause())

        # ğŸ”§ ä½¿ç”¨å¢å¼ºçš„ç³»ç»Ÿæç¤ºï¼ˆå¦‚æœæ˜¯æ–‡æ¡£ä»»åŠ¡ï¼‰
        if is_document_task and (has_info_from_history or has_reference_info or is_html_task or is_pdf_task):
            system_prompt_coder = enhanced_system_prompt
        else:
            system_prompt_coder = self.system_prompt_coder_template.format(
                date_today=datetime.now().strftime("%Y-%m-%d")  # ğŸ”§ ä¿®å¤ï¼šåªéœ€è¦date_todayå‚æ•°
            )

        try:
            executed_code = False
            # Run the code execution and debugging process.
            async for msg in _coding_and_debug(
                system_prompt=system_prompt_coder,
                thread=self._chat_history,
                agent_name=self.name,
                model_client=self._model_client,
                code_executor=self._code_executor,
                max_debug_rounds=self._max_debug_rounds,
                cancellation_token=code_execution_token,
                model_context=self._model_context,
                approval_guard=self._approval_guard,
            ):
                if isinstance(msg, bool):
                    executed_code = msg
                    break
                inner_messages.append(msg)
                self._chat_history.append(msg)
                yield msg

            # New conditional block based on the configuration flag.
            if self._summarize_output and executed_code:
                summary_msg = await _summarize_coding(
                    agent_name=self.name,
                    model_client=self._model_client,
                    thread=[last_message_received] + inner_messages,
                    cancellation_token=code_execution_token,
                    model_context=self._model_context,
                )
                self._chat_history.append(summary_msg)
                yield Response(chat_message=summary_msg, inner_messages=inner_messages)
            else:
                # Instead of only executor output, return a transcript of all code and execution steps.
                combined_output = ""
                for txt_msg in inner_messages:
                    assert isinstance(txt_msg, TextMessage)
                    combined_output += f"{txt_msg.content}\n"
                
                # ğŸ”§ æ–°å¢ï¼šä¸ºæ–‡æ¡£åˆ›å»ºä»»åŠ¡æä¾›æ›´æ˜ç¡®çš„å®Œæˆç¡®è®¤
                if is_document_task and executed_code:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶åˆ›å»ºçš„è¯æ®
                    file_creation_evidence = any(keyword in combined_output.lower() for keyword in [
                        "ä¿å­˜", "åˆ›å»º", "æ–‡ä»¶", "saved", "created", ".md", ".html", ".pdf",
                        "write_text", "write_pdf", "å·²ç”Ÿæˆ", "successfully", "å®Œæˆ"
                    ])
                    
                    if file_creation_evidence:
                        if is_pdf_task:
                            combined_output += "\n\nâœ… **PDFæ–‡æ¡£åˆ›å»ºä»»åŠ¡å·²å®Œæˆ**ï¼äº§å“ä»‹ç»PDFæ–‡ä»¶å·²æˆåŠŸç”Ÿæˆã€‚"
                        elif is_html_task:
                            combined_output += "\n\nâœ… **HTMLæ–‡æ¡£åˆ›å»ºä»»åŠ¡å·²å®Œæˆ**ï¼äº§å“ä»‹ç»HTMLæ–‡ä»¶å·²æˆåŠŸç”Ÿæˆã€‚"
                        else:
                            combined_output += "\n\nâœ… **æ–‡æ¡£åˆ›å»ºä»»åŠ¡å·²å®Œæˆ**ï¼äº§å“ä»‹ç»æ–‡æ¡£å·²æˆåŠŸç”Ÿæˆã€‚"
                    else:
                        combined_output += "\n\nğŸ“ æ–‡æ¡£åˆ›å»ºè¿‡ç¨‹å·²æ‰§è¡Œï¼Œè¯·æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶ã€‚"
                
                final_response_msg = TextMessage(
                    source=self.name,
                    metadata={"internal": "yes"},
                    content=combined_output or "No output.",
                )
                # TODO: do we not want to add this to the chat history?
                yield Response(
                    chat_message=final_response_msg, inner_messages=inner_messages
                )
        except ApprovalDeniedError:
            # If the user denies the approval, we respond with a message.
            yield Response(
                chat_message=TextMessage(
                    content="The user did not approve the code execution.",
                    source=self.name,
                    metadata={"internal": "no"},
                ),
                inner_messages=inner_messages,
            )
        except asyncio.CancelledError:
            # If the task is cancelled, we respond with a message.
            yield Response(
                chat_message=TextMessage(
                    content="The task was cancelled by the user.",
                    source=self.name,
                    metadata={"internal": "yes"},
                ),
                inner_messages=inner_messages,
            )
        except Exception as e:
            logger.error(f"Error in CoderAgent: {e}")
            # add to chat history
            self._chat_history.append(
                TextMessage(
                    content=f"An error occurred while executing the code: {e}",
                    source=self.name,
                )
            )
            yield Response(
                chat_message=TextMessage(
                    content=f"An error occurred in the coder agent: {e}",
                    source=self.name,
                    metadata={"internal": "no"},
                ),
                inner_messages=inner_messages,
            )
        finally:
            # Cancel the monitor task.
            try:
                monitor_pause_task.cancel()
                await monitor_pause_task
            except asyncio.CancelledError:
                pass

    async def on_reset(self, cancellation_token: CancellationToken) -> None:
        """Clear the chat history."""
        self._chat_history.clear()

    def _to_config(self) -> CoderAgentConfig:
        """Convert the agent's state to a configuration object."""
        return CoderAgentConfig(
            name=self.name,
            model_client=self._model_client.dump_component(),
            description=self.description,
            max_debug_rounds=self._max_debug_rounds,
            summarize_output=self._summarize_output,
            # TODO: Optionally add code_executor configuration if supported
        )

    @classmethod
    def _from_config(cls, config: CoderAgentConfig) -> Self:
        """Create an agent instance from a configuration object."""
        return cls(
            name=config.name,
            model_client=ChatCompletionClient.load_component(config.model_client),
            description=config.description,
            max_debug_rounds=config.max_debug_rounds,
            summarize_output=config.summarize_output,
            # TODO: Optionally load code_executor from config if provided
        )

    async def save_state(self) -> Mapping[str, Any]:
        """
        Save the state of the agent.
        """
        return {
            "chat_history": [msg.dump() for msg in self._chat_history],
        }

    async def load_state(self, state: Mapping[str, Any]) -> None:
        """
        Load the state of the agent.
        """
        # Create message factory for deserialization.
        message_factory = MessageFactory()
        for msg_data in state["chat_history"]:
            msg = message_factory.create(msg_data)
            assert isinstance(msg, BaseChatMessage)
            self._chat_history.append(msg)
